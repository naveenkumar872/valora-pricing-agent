from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from bs4 import BeautifulSoup
import time

# ‚úÖ New Flipkart price class
PRICE_CLASS = "Nx9bqj"

def extract_discounted_prices_only(html):
    soup = BeautifulSoup(html, "html.parser")
    prices = []

    for tag in soup.find_all("div", class_=PRICE_CLASS):
        price_text = tag.get_text(strip=True).replace("‚Çπ", "").replace(",", "")
        if price_text.isdigit():
            prices.append(int(price_text))

    print(f"‚úÖ Found {len(prices)} raw prices from HTML.")
    unique_prices = sorted(set(prices))
    print(f"üîÅ Final unique prices (‚Çπ): {unique_prices}")
    return unique_prices

def scrape_flipkart_prices(query: str,page : int):
    print(f"\nüîé Scrolling Flipkart for query: '{query}'")

    options = Options()
    # options.add_argument("--headless")  # enable for silent scraping
    options.add_argument("--disable-gpu")
    options.add_argument("--no-sandbox")
    options.add_argument("--window-size=1920,1200")
    options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64)")
    options.add_experimental_option("excludeSwitches", ["enable-logging"])

    driver = webdriver.Chrome(service=Service(), options=options)

    url = f"https://www.flipkart.com/search?q={query.replace(' ', '+')}&sort=price_asc&page={page}"
    print(f"üåê Opening URL: {url}")
    driver.get(url)
    time.sleep(3)

    # ‚úÖ Try closing login popup
    try:
        close_btn = driver.find_element(By.XPATH, "//button[contains(text(), '‚úï')]")
        close_btn.click()
        print("‚úÖ Login popup closed")
        time.sleep(1)
    except:
        print("‚ÑπÔ∏è No login popup")

    # ‚úÖ Scroll multiple times to load content
    
    driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
       
    time.sleep(2)

    # ‚úÖ Wait until price class is detected in page source
    try:
        WebDriverWait(driver, 10).until(lambda d: PRICE_CLASS in d.page_source)
        print(f"üü¢ Price class '{PRICE_CLASS}' found")
    except:
        print(f"‚ö†Ô∏è Price class '{PRICE_CLASS}' NOT found in time")

    # ‚úÖ Save HTML
    html = driver.page_source
    with open("flipkart_dump.html", "w", encoding="utf-8") as f:
        f.write(html)
        print("üìù HTML saved to flipkart_dump_scroll.html")

    driver.quit()

    # ‚úÖ Extract prices from soup
    return extract_discounted_prices_only(html)

